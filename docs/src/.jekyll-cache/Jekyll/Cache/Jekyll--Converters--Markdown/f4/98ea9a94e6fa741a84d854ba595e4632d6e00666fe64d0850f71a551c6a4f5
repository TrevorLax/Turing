I"D<h1 id="advanced-usage">Advanced Usage</h1>

<h2 id="how-to-define-a-customized-distribution">How to Define a Customized Distribution</h2>

<p>Turing.jl supports the use of distributions from the Distributions.jl package. By extension it also supports the use of customized distributions, by defining them as subtypes of <code class="language-plaintext highlighter-rouge">Distribution</code> type of the Distributions.jl package, as well as corresponding functions.</p>

<p>Below shows a workflow of how to define a customized distribution, using our own implementation of a simple <code class="language-plaintext highlighter-rouge">Uniform</code> distribution as a simple example.</p>

<h3 id="1-define-the-distribution-type">1. Define the Distribution Type</h3>

<p>First, define a type of the distribution, as a subtype of a corresponding distribution type in the Distributions.jl package.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span><span class="nc"> CustomUniform</span> <span class="o">&lt;:</span> <span class="n">ContinuousUnivariateDistribution</span>
<span class="k">end</span>
</code></pre></div></div>

<h3 id="2-implement-sampling-and-evaluation-of-the-log-pdf">2. Implement Sampling and Evaluation of the log-pdf</h3>

<p>Second, define <code class="language-plaintext highlighter-rouge">rand</code> and <code class="language-plaintext highlighter-rouge">logpdf</code>, which will be used to run the model.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Distributions</span><span class="o">.</span><span class="n">rand</span><span class="x">(</span><span class="n">rng</span><span class="o">::</span><span class="kt">AbstractRNG</span><span class="x">,</span> <span class="n">d</span><span class="o">::</span><span class="n">CustomUniform</span><span class="x">)</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="n">rng</span><span class="x">)</span> <span class="c"># sample in [0, 1]</span>
<span class="n">Distributions</span><span class="o">.</span><span class="n">logpdf</span><span class="x">(</span><span class="n">d</span><span class="o">::</span><span class="n">CustomUniform</span><span class="x">,</span> <span class="n">x</span><span class="o">::</span><span class="kt">Real</span><span class="x">)</span> <span class="o">=</span> <span class="n">zero</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>          <span class="c"># p(x) = 1 ‚Üí logp(x) = 0</span>
</code></pre></div></div>

<h3 id="3-define-helper-functions">3. Define Helper Functions</h3>

<p>In most cases, it may be required to define some helper functions.</p>

<h4 id="31-domain-transformation">3.1 Domain Transformation</h4>

<p>Certain samplers, such as <code class="language-plaintext highlighter-rouge">HMC</code>, require the domain of the priors to be unbounded. Therefore, to use our <code class="language-plaintext highlighter-rouge">CustomUniform</code> as a prior in a model we also need to define how to transform samples from <code class="language-plaintext highlighter-rouge">[0, 1]</code> to <code class="language-plaintext highlighter-rouge">‚Ñù</code>. To do this, we simply need to define the corresponding <code class="language-plaintext highlighter-rouge">Bijector</code> from <code class="language-plaintext highlighter-rouge">Bijectors.jl</code>, which is what <code class="language-plaintext highlighter-rouge">Turing.jl</code> uses internally to deal with constrained distributions.</p>

<p>To transform from <code class="language-plaintext highlighter-rouge">[0, 1]</code> to <code class="language-plaintext highlighter-rouge">‚Ñù</code> we can use the <code class="language-plaintext highlighter-rouge">Logit</code> bijector:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Bijectors</span><span class="o">.</span><span class="n">bijector</span><span class="x">(</span><span class="n">d</span><span class="o">::</span><span class="n">CustomUniform</span><span class="x">)</span> <span class="o">=</span> <span class="n">Logit</span><span class="x">(</span><span class="mf">0.</span><span class="x">,</span> <span class="mf">1.</span><span class="x">)</span>
</code></pre></div></div>

<p>You‚Äôd do the exact same thing for <code class="language-plaintext highlighter-rouge">ContinuousMultivariateDistribution</code> and <code class="language-plaintext highlighter-rouge">ContinuousMatrixDistribution</code>. For example, <code class="language-plaintext highlighter-rouge">Wishart</code> defines a distribution over positive-definite matrices and so <code class="language-plaintext highlighter-rouge">bijector</code> returns a <code class="language-plaintext highlighter-rouge">PDBijector</code> when called with a <code class="language-plaintext highlighter-rouge">Wishart</code> distribution as an argument. For discrete distributions, there is no need to define a bijector; the <code class="language-plaintext highlighter-rouge">Identity</code> bijector is used by default.</p>

<p>Alternatively, for <code class="language-plaintext highlighter-rouge">UnivariateDistribution</code> we can define the <code class="language-plaintext highlighter-rouge">minimum</code> and <code class="language-plaintext highlighter-rouge">maximum</code> of the distribution</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Distributions</span><span class="o">.</span><span class="n">minimum</span><span class="x">(</span><span class="n">d</span><span class="o">::</span><span class="n">CustomUniform</span><span class="x">)</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">Distributions</span><span class="o">.</span><span class="n">maximum</span><span class="x">(</span><span class="n">d</span><span class="o">::</span><span class="n">CustomUniform</span><span class="x">)</span> <span class="o">=</span> <span class="mf">1.</span>
</code></pre></div></div>

<p>and <code class="language-plaintext highlighter-rouge">Bijectors.jl</code> will return a default <code class="language-plaintext highlighter-rouge">Bijector</code> called <code class="language-plaintext highlighter-rouge">TruncatedBijector</code> which makes use of <code class="language-plaintext highlighter-rouge">minimum</code> and <code class="language-plaintext highlighter-rouge">maximum</code> derive the correct transformation.</p>

<p>Internally, Turing basically does the following when it needs to convert a constrained distribution to an unconstrained distribution, e.g. when sampling using <code class="language-plaintext highlighter-rouge">HMC</code>:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">b</span> <span class="o">=</span> <span class="n">bijector</span><span class="x">(</span><span class="n">dist</span><span class="x">)</span>
<span class="n">transformed_dist</span> <span class="o">=</span> <span class="n">transformed</span><span class="x">(</span><span class="n">dist</span><span class="x">,</span> <span class="n">b</span><span class="x">)</span> <span class="c"># results in distribution with transformed support + correction for logpdf</span>
</code></pre></div></div>
<p>and then we can call <code class="language-plaintext highlighter-rouge">rand</code> and <code class="language-plaintext highlighter-rouge">logpdf</code> as usual, where</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">rand(transformed_dist)</code> returns a sample in the unconstrained space, and</li>
  <li><code class="language-plaintext highlighter-rouge">logpdf(transformed_dist, y)</code> returns the log density of the original distribution, but with <code class="language-plaintext highlighter-rouge">y</code> living in the unconstrained space.</li>
</ul>

<p>To read more about Bijectors.jl, check out <a href="https://github.com/TuringLang/Bijectors.jl">the project README</a>.</p>

<h4 id="32-vectorization-support">3.2 Vectorization Support</h4>

<p>The vectorization syntax follows <code class="language-plaintext highlighter-rouge">rv ~ [distribution]</code>, which requires <code class="language-plaintext highlighter-rouge">rand</code> and <code class="language-plaintext highlighter-rouge">logpdf</code> to be called on multiple data points at once. An appropriate implementation for <code class="language-plaintext highlighter-rouge">Flat</code> is shown below.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Distributions</span><span class="o">.</span><span class="n">logpdf</span><span class="x">(</span><span class="n">d</span><span class="o">::</span><span class="n">Flat</span><span class="x">,</span> <span class="n">x</span><span class="o">::</span><span class="kt">AbstractVector</span><span class="x">{</span><span class="o">&lt;:</span><span class="kt">Real</span><span class="x">})</span> <span class="o">=</span> <span class="n">zero</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="model-internals">Model Internals</h2>

<p>The <code class="language-plaintext highlighter-rouge">@model</code> macro accepts a function definition and generates a <code class="language-plaintext highlighter-rouge">Turing.Model</code> struct for use by the sampler. Models can be constructed by hand without the use of a macro. Taking the <code class="language-plaintext highlighter-rouge">gdemo</code> model as an example, the two code sections below (macro and macro-free) are equivalent.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Turing</span>

<span class="nd">@model</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="c"># Set priors.</span>
  <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
  <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>

  <span class="c"># Observe each value of x.</span>
  <span class="nd">@.</span> <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>

<span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">]),</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.1</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Turing</span>

<span class="c"># Initialize a NamedTuple containing our data variables.</span>
<span class="n">data</span> <span class="o">=</span> <span class="x">(</span><span class="n">x</span> <span class="o">=</span> <span class="x">[</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">],)</span>

<span class="c"># Create the model function.</span>
<span class="n">mf</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">sampler</span><span class="x">,</span> <span class="n">ctx</span><span class="x">,</span> <span class="n">model</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="c"># Set the accumulated logp to zero.</span>
    <span class="n">resetlogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">x</span>

    <span class="c"># Assume s has an InverseGamma distribution.</span>
    <span class="n">s</span><span class="x">,</span> <span class="n">lp</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">tilde</span><span class="x">(</span>
        <span class="n">ctx</span><span class="x">,</span>
        <span class="n">sampler</span><span class="x">,</span>
        <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">),</span>
        <span class="n">Turing</span><span class="o">.</span><span class="nd">@varname</span><span class="x">(</span><span class="n">s</span><span class="x">),</span>
        <span class="x">(),</span>
        <span class="n">vi</span><span class="x">,</span>
    <span class="x">)</span>

    <span class="c"># Add the lp to the accumulated logp.</span>
    <span class="n">acclogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">lp</span><span class="x">)</span>

    <span class="c"># Assume m has a Normal distribution.</span>
    <span class="n">m</span><span class="x">,</span> <span class="n">lp</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">tilde</span><span class="x">(</span>
        <span class="n">ctx</span><span class="x">,</span>
        <span class="n">sampler</span><span class="x">,</span>
        <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">)),</span>
        <span class="n">Turing</span><span class="o">.</span><span class="nd">@varname</span><span class="x">(</span><span class="n">m</span><span class="x">),</span>
        <span class="x">(),</span>
        <span class="n">vi</span><span class="x">,</span>
    <span class="x">)</span>

    <span class="c"># Add the lp to the accumulated logp.</span>
    <span class="n">acclogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">lp</span><span class="x">)</span>

    <span class="c"># Observe each value of x[i], according to a</span>
    <span class="c"># Normal distribution.</span>
    <span class="n">lp</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">dot_tilde</span><span class="x">(</span><span class="n">ctx</span><span class="x">,</span> <span class="n">sampler</span><span class="x">,</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">)),</span> <span class="n">x</span><span class="x">,</span> <span class="n">vi</span><span class="x">)</span>
    <span class="n">acclogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">lp</span><span class="x">)</span>
<span class="k">end</span>

<span class="c"># Instantiate a Model object.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DynamicPPL</span><span class="o">.</span><span class="n">Model</span><span class="x">(</span><span class="n">mf</span><span class="x">,</span> <span class="n">data</span><span class="x">,</span> <span class="n">DyanamicPPL</span><span class="o">.</span><span class="n">ModelGen</span><span class="x">{()}(</span><span class="nb">nothing</span><span class="x">,</span> <span class="nb">nothing</span><span class="x">))</span>

<span class="c"># Sample the model.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.1</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<h2 id="task-copying">Task Copying</h2>

<p>Turing <a href="https://github.com/JuliaLang/julia/issues/4085">copies</a> Julia tasks to deliver efficient inference algorithms, but it also provides alternative slower implementation as a fallback. Task copying is enabled by default. Task copying requires we use the <code class="language-plaintext highlighter-rouge">CTask</code> facility which is provided by <a href="https://github.com/TuringLang/Libtask.jl">Libtask</a> to create tasks.</p>

:ET