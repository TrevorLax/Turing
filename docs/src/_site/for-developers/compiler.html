<p>In this section, I will describe the current design of Turing’s model compiler which enables Turing to perform various types of Bayesian inference without changing the model definition. What we call “compiler” is essentially just a macro that transforms the user’s code to something that Julia’s dispatch can operate on and that Julia’s compiler can successfully do type inference on for efficient machine code generation.</p>

<h1 id="overview">Overview</h1>

<p>The following terminology will be used in this section:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">D</code>: observed data variables conditioned upon in the posterior,</li>
  <li><code class="language-plaintext highlighter-rouge">P</code>: parameter variables distributed according to the prior distributions, these will also be referred to as random variables,</li>
  <li><code class="language-plaintext highlighter-rouge">Model</code>: a fully defined probabilistic model with input data, and</li>
  <li><code class="language-plaintext highlighter-rouge">ModelGen</code>: a model generator function that can be used to instantiate a <code class="language-plaintext highlighter-rouge">Model</code> instance by inputing data <code class="language-plaintext highlighter-rouge">D</code>.</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">Turing</code>’s <code class="language-plaintext highlighter-rouge">@model</code> macro defines a <code class="language-plaintext highlighter-rouge">ModelGen</code> that can be used to instantiate a <code class="language-plaintext highlighter-rouge">Model</code> by passing in the observed data <code class="language-plaintext highlighter-rouge">D</code>.</p>

<h1 id="model-macro-and-modelgen"><code class="language-plaintext highlighter-rouge">@model</code> macro and <code class="language-plaintext highlighter-rouge">ModelGen</code></h1>

<p>The following are the main jobs of the <code class="language-plaintext highlighter-rouge">@model</code> macro:</p>
<ol>
  <li>Parse <code class="language-plaintext highlighter-rouge">~</code> and <code class="language-plaintext highlighter-rouge">.~</code> lines, e.g. <code class="language-plaintext highlighter-rouge">y .~ Normal.(c*x, 1.0)</code></li>
  <li>Figure out if a variable belongs to the data <code class="language-plaintext highlighter-rouge">D</code> and or to the parameters <code class="language-plaintext highlighter-rouge">P</code></li>
  <li>Enable the handling of missing data variables in <code class="language-plaintext highlighter-rouge">D</code> when defining a <code class="language-plaintext highlighter-rouge">Model</code> and treating them as parameter variables in <code class="language-plaintext highlighter-rouge">P</code> instead</li>
  <li>Enable the tracking of random variables using the data structures <code class="language-plaintext highlighter-rouge">VarName</code> and <code class="language-plaintext highlighter-rouge">VarInfo</code></li>
  <li>Change <code class="language-plaintext highlighter-rouge">~</code>/<code class="language-plaintext highlighter-rouge">.~</code> lines with a variable in <code class="language-plaintext highlighter-rouge">P</code> on the LHS to a call to an <code class="language-plaintext highlighter-rouge">assume</code>/<code class="language-plaintext highlighter-rouge">dot_assume</code>-block</li>
  <li>Change <code class="language-plaintext highlighter-rouge">~</code>/<code class="language-plaintext highlighter-rouge">.~</code> lines with a variable in <code class="language-plaintext highlighter-rouge">D</code> on the LHS to a call to an <code class="language-plaintext highlighter-rouge">observe</code>/<code class="language-plaintext highlighter-rouge">dot_observe</code>-block</li>
  <li>Enable type stable automatic differentiation of the model using type parameters</li>
</ol>

<p>Let’s take the following model as an example:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">gauss</span><span class="x">(</span><span class="n">x</span> <span class="o">=</span> <span class="nb">missing</span><span class="x">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.0</span><span class="x">,</span> <span class="o">::</span><span class="kt">Type</span><span class="x">{</span><span class="n">TV</span><span class="x">}</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">})</span> <span class="k">where</span> <span class="x">{</span><span class="n">TV</span> <span class="o">&lt;:</span> <span class="kt">AbstractVector</span><span class="x">}</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">===</span> <span class="nb">missing</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">TV</span><span class="x">(</span><span class="nb">undef</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="k">end</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">TV</span><span class="x">(</span><span class="nb">undef</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
    <span class="n">p</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
    <span class="n">p</span><span class="x">[</span><span class="mi">2</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mf">1.0</span><span class="x">)</span>
    <span class="nd">@.</span> <span class="n">x</span><span class="x">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">2</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">p</span><span class="x">[</span><span class="mi">2</span><span class="x">],</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">p</span><span class="x">[</span><span class="mi">1</span><span class="x">]))</span>
    <span class="n">x</span><span class="x">[</span><span class="mi">3</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">()</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">p</span><span class="x">[</span><span class="mi">2</span><span class="x">],</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">p</span><span class="x">[</span><span class="mi">1</span><span class="x">]))</span>
<span class="k">end</span>
</code></pre></div></div>
<p>The above call of the <code class="language-plaintext highlighter-rouge">@model</code> macro defines an instance of <code class="language-plaintext highlighter-rouge">ModelGen</code> called <code class="language-plaintext highlighter-rouge">gauss</code>. A <code class="language-plaintext highlighter-rouge">model::Model</code> can be defined using <code class="language-plaintext highlighter-rouge">gauss(rand(3), 1.0)</code> or <code class="language-plaintext highlighter-rouge">gauss(x = rand(3), y = 1.0)</code>. While constructing the model, if an argument is not passed in, it gets assigned to its default value. If there is no default value given, an error is thrown. If an argument has a default value <code class="language-plaintext highlighter-rouge">missing</code>, when not passed in, it is treated as a random variable. For variables which require an intialization because we need to loop or broadcast over its elements, such as <code class="language-plaintext highlighter-rouge">x</code> above, the following needs to be done:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">x</span> <span class="o">===</span> <span class="nb">missing</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>
<span class="k">end</span>
</code></pre></div></div>
<p>If <code class="language-plaintext highlighter-rouge">x</code> is sampled as a whole from a multivariate distribution, e.g. <code class="language-plaintext highlighter-rouge">x ~ MvNormal(...)</code>, there is no need to initialize it in an <code class="language-plaintext highlighter-rouge">if</code>-block.</p>

<p><code class="language-plaintext highlighter-rouge">ModelGen</code> is defined as:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span><span class="nc"> ModelGen</span><span class="x">{</span><span class="n">Targs</span><span class="x">,</span> <span class="n">F</span><span class="x">,</span> <span class="n">Tdefaults</span><span class="x">}</span> <span class="o">&lt;:</span> <span class="kt">Function</span>
    <span class="n">f</span><span class="o">::</span><span class="n">F</span>
    <span class="n">defaults</span><span class="o">::</span><span class="n">Tdefaults</span>
<span class="k">end</span>
<span class="n">ModelGen</span><span class="x">{</span><span class="n">Targs</span><span class="x">}(</span><span class="n">args</span><span class="o">...</span><span class="x">)</span> <span class="k">where</span> <span class="x">{</span><span class="n">Targs</span><span class="x">}</span> <span class="o">=</span> <span class="n">ModelGen</span><span class="x">{</span><span class="n">Targs</span><span class="x">,</span> <span class="n">typeof</span><span class="o">.</span><span class="x">(</span><span class="n">args</span><span class="x">)</span><span class="o">...</span><span class="x">}(</span><span class="n">args</span><span class="o">...</span><span class="x">)</span>
<span class="x">(</span><span class="n">m</span><span class="o">::</span><span class="n">ModelGen</span><span class="x">)(</span><span class="n">args</span><span class="o">...</span><span class="x">;</span> <span class="n">kwargs</span><span class="o">...</span><span class="x">)</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">f</span><span class="x">(</span><span class="n">args</span><span class="o">...</span><span class="x">;</span> <span class="n">kwargs</span><span class="o">...</span><span class="x">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">Targs</code> is the tuple of the symbols of the model’s arguments, <code class="language-plaintext highlighter-rouge">(:x, :y, :TV)</code>. <code class="language-plaintext highlighter-rouge">defaults</code> is the <code class="language-plaintext highlighter-rouge">NamedTuple</code> of default values <code class="language-plaintext highlighter-rouge">(x = missing, y = 1.0, TV = Vector{Float64})</code>.</p>

<p>The <code class="language-plaintext highlighter-rouge">@model</code> macro is defined as:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">macro</span><span class="nf"> model</span><span class="x">(</span><span class="n">input_expr</span><span class="x">)</span>
    <span class="n">build_model_info</span><span class="x">(</span><span class="n">input_expr</span><span class="x">)</span> <span class="o">|&gt;</span> <span class="n">replace_tilde!</span> <span class="o">|&gt;</span> <span class="n">replace_vi!</span> <span class="o">|&gt;</span> 
        <span class="n">replace_logpdf!</span> <span class="o">|&gt;</span> <span class="n">replace_sampler!</span> <span class="o">|&gt;</span> <span class="n">build_output</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="build_model_info"><code class="language-plaintext highlighter-rouge">build_model_info</code></h2>

<p>The first stop that the model definition takes is <code class="language-plaintext highlighter-rouge">build_model_info</code>. This function extracts some information from the model definition such as:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">name</code>: the model name.</li>
  <li><code class="language-plaintext highlighter-rouge">main_body</code>: the model body excluding the header and <code class="language-plaintext highlighter-rouge">end</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">arg_syms</code>: the argument symbols, e.g. <code class="language-plaintext highlighter-rouge">[:x, :y, :TV]</code> above.</li>
  <li><code class="language-plaintext highlighter-rouge">args</code>: a modified version of the arguments changing <code class="language-plaintext highlighter-rouge">::Type{TV}=Vector{Float64}</code> and <code class="language-plaintext highlighter-rouge">where {TV &lt;: AbstractVector}</code> to <code class="language-plaintext highlighter-rouge">TV::Type{&lt;:AbstractVector}=Vector{Float64}</code>. This is <code class="language-plaintext highlighter-rouge">[:(x = missing) :(y = 1.0), :(TV::Type{&lt;:AbstractVector}=Vector{Float64})]</code> in the example above.</li>
  <li><code class="language-plaintext highlighter-rouge">args_nt</code>: an expression constructing a <code class="language-plaintext highlighter-rouge">NamedTuple</code> of the input arguments, e.g. :((x = x, y = y, TV = TV)) in the example above.</li>
  <li><code class="language-plaintext highlighter-rouge">defaults_nt</code>: an expression constructing a <code class="language-plaintext highlighter-rouge">NamedTuple</code> of the default values of the input arguments, if any, e.g. :((x = missing, y = 1, TV = Vector{Float64})) in the example above.
and returns it as a dictionary called <code class="language-plaintext highlighter-rouge">model_info</code>.</li>
</ul>

<h2 id="replace_tilde"><code class="language-plaintext highlighter-rouge">replace_tilde!</code></h2>

<p>After some model information have been extracted, <code class="language-plaintext highlighter-rouge">replace_tilde!</code> replaces the <code class="language-plaintext highlighter-rouge">L ~ R</code> lines in the model with the output of <code class="language-plaintext highlighter-rouge">Core.tilde(L, R, model_info)</code> where <code class="language-plaintext highlighter-rouge">L</code> and <code class="language-plaintext highlighter-rouge">R</code> are either expressions or symbols. <code class="language-plaintext highlighter-rouge">L</code> can also be a constant literal. The <code class="language-plaintext highlighter-rouge">replace_tilde!</code> function also replaces expressions of the form <code class="language-plaintext highlighter-rouge">@. L ~ R</code> with the output of <code class="language-plaintext highlighter-rouge">dot_tilde(L, R, model_info)</code>.</p>

<p>In the above example, <code class="language-plaintext highlighter-rouge">p[1] ~ InverseGamma(2, 3)</code> is replaced with:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">temp_right</span> <span class="o">=</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">)</span>
<span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="n">assert_dist</span><span class="x">(</span><span class="n">temp_right</span><span class="x">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="o">...</span><span class="x">)</span>
<span class="n">preprocessed</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="nd">@preprocess</span><span class="x">(</span><span class="kt">Val</span><span class="x">((</span><span class="o">:</span><span class="n">x</span><span class="x">,</span> <span class="o">:</span><span class="n">y</span><span class="x">,</span> <span class="o">:</span><span class="n">T</span><span class="x">)),</span> <span class="n">Turing</span><span class="o">.</span><span class="n">getmissing</span><span class="x">(</span><span class="n">model</span><span class="x">),</span> <span class="n">p</span><span class="x">[</span><span class="mi">1</span><span class="x">])</span>
<span class="k">if</span> <span class="n">preprocessed</span> <span class="k">isa</span> <span class="kt">Tuple</span>
    <span class="n">vn</span><span class="x">,</span> <span class="n">inds</span> <span class="o">=</span> <span class="n">preprocessed</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">tilde</span><span class="x">(</span><span class="n">ctx</span><span class="x">,</span> <span class="n">sampler</span><span class="x">,</span> <span class="n">temp_right</span><span class="x">,</span> <span class="n">vn</span><span class="x">,</span> <span class="n">inds</span><span class="x">,</span> <span class="n">vi</span><span class="x">)</span>
    <span class="n">p</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span> <span class="o">=</span> <span class="n">out</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span>
    <span class="n">acclogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">out</span><span class="x">[</span><span class="mi">2</span><span class="x">])</span>
<span class="k">else</span>
    <span class="n">lp</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">tilde</span><span class="x">(</span><span class="n">ctx</span><span class="x">,</span> <span class="n">sampler</span><span class="x">,</span> <span class="n">temp_right</span><span class="x">,</span> <span class="n">preprocessed</span><span class="x">,</span> <span class="n">vi</span><span class="x">)</span>
    <span class="n">acclogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">lp</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>
<p>where <code class="language-plaintext highlighter-rouge">ctx::AbstractContext</code>, <code class="language-plaintext highlighter-rouge">sampler::AbstractSampler</code> and <code class="language-plaintext highlighter-rouge">vi::VarInfo</code> will be discussed later. <code class="language-plaintext highlighter-rouge">assert_dist</code> will check that the RHS of <code class="language-plaintext highlighter-rouge">~</code> is a distribution otherwise an error is thrown. The <code class="language-plaintext highlighter-rouge">@preprocess</code> macro here checks:</p>
<ol>
  <li>If the symbol on the LHS of <code class="language-plaintext highlighter-rouge">~</code>, <code class="language-plaintext highlighter-rouge">:p</code> in this case, is in the arguments to the model, <code class="language-plaintext highlighter-rouge">(:x, :y, :T)</code>, or not. If it isn’t, then <code class="language-plaintext highlighter-rouge">p[1]</code> will be treated as a random variable.</li>
  <li>If it is in the arguments but was among the arguments with a value of <code class="language-plaintext highlighter-rouge">missing</code>, obtained using <code class="language-plaintext highlighter-rouge">getmissing(model)</code>, then <code class="language-plaintext highlighter-rouge">p[1]</code> is also treated as a random variable.</li>
  <li>If neither of the above is true, but the value of <code class="language-plaintext highlighter-rouge">p[1]</code> is <code class="language-plaintext highlighter-rouge">missing</code>, then <code class="language-plaintext highlighter-rouge">p[1]</code> will still be treated as a random variable.</li>
  <li>Otherwise, <code class="language-plaintext highlighter-rouge">p[1]</code> is treated as an observation.</li>
</ol>

<p>If <code class="language-plaintext highlighter-rouge">@preprocess</code> treats <code class="language-plaintext highlighter-rouge">p[1]</code> as a random variable, it will return a <code class="language-plaintext highlighter-rouge">2-Tuple</code> of: 1) a variable identifier <code class="language-plaintext highlighter-rouge">vn::VarName = Turing.@varname p[1]</code>, and 2) a tuple of tuples of the indices used in <code class="language-plaintext highlighter-rouge">vn</code>, <code class="language-plaintext highlighter-rouge">((1,),)</code> in this example. Otherwise, <code class="language-plaintext highlighter-rouge">@preprocess</code> returns the value of <code class="language-plaintext highlighter-rouge">p[1]</code>. <code class="language-plaintext highlighter-rouge">Turing.@varname</code> and <code class="language-plaintext highlighter-rouge">VarName</code> wil be explained later. The above checks by <code class="language-plaintext highlighter-rouge">@preprocess</code> were carefully written to make sure that the Julia compiler can compile them away so no checks happen at runtime and only the correct branch is run straight away.</p>

<p>When the output of <code class="language-plaintext highlighter-rouge">@preprocess</code> is a <code class="language-plaintext highlighter-rouge">Tuple</code>, i.e. <code class="language-plaintext highlighter-rouge">p[1]</code> is a random variable, the <code class="language-plaintext highlighter-rouge">Turing.Inference.tilde</code> function will dispatch to a different method than when the output is of another type, i.e <code class="language-plaintext highlighter-rouge">p[1]</code> is an observation. In the former case, <code class="language-plaintext highlighter-rouge">Turing.Inference.tilde</code> returns 2 outputs, the value of the random variable and the <code class="language-plaintext highlighter-rouge">log</code> probability, while in the latter case, only the <code class="language-plaintext highlighter-rouge">log</code> probability is returned. The <code class="language-plaintext highlighter-rouge">log</code> probabilities then get accumulated and if <code class="language-plaintext highlighter-rouge">p[1]</code> is a random variable, the first returned output by <code class="language-plaintext highlighter-rouge">Turing.Inference.tilde</code> gets assigned to it.</p>

<p>Note that <code class="language-plaintext highlighter-rouge">Core.tilde</code> is different from <code class="language-plaintext highlighter-rouge">Inference.tilde</code>. <code class="language-plaintext highlighter-rouge">Core.tilde</code> returns the expression block that will be run instead of the <code class="language-plaintext highlighter-rouge">~</code> line. A part of this expression block is a call to <code class="language-plaintext highlighter-rouge">Inference.tilde</code> as shown above. <code class="language-plaintext highlighter-rouge">Core.tilde</code> is defined in the <code class="language-plaintext highlighter-rouge">compiler.jl</code> file, while <code class="language-plaintext highlighter-rouge">Inference.tilde</code> is defined in the <code class="language-plaintext highlighter-rouge">Inference.jl</code> file.</p>

<p>The <code class="language-plaintext highlighter-rouge">dot_tilde!</code> function does something similar for expressions of the form <code class="language-plaintext highlighter-rouge">@. L ~ R</code> (and <code class="language-plaintext highlighter-rouge">L .~ R</code> in Julia 1.1 and above). Let’s take <code class="language-plaintext highlighter-rouge">@. x[1:2] ~ Normal(p[2], sqrt(p[1]))</code> as an example. This expressions replaced with:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">temp_right</span> <span class="o">=</span> <span class="n">Normal</span><span class="x">(</span><span class="n">p</span><span class="x">[</span><span class="mi">2</span><span class="x">],</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">p</span><span class="x">[</span><span class="mi">1</span><span class="x">]))</span>
<span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="n">assert_dist</span><span class="x">(</span><span class="n">temp_right</span><span class="x">,</span> <span class="n">msg</span> <span class="o">=</span> <span class="o">...</span><span class="x">)</span>
<span class="n">preprocessed</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="nd">@preprocess</span><span class="x">(</span><span class="kt">Val</span><span class="x">((</span><span class="o">:</span><span class="n">x</span><span class="x">,</span> <span class="o">:</span><span class="n">y</span><span class="x">,</span> <span class="o">:</span><span class="n">T</span><span class="x">)),</span> <span class="n">Turing</span><span class="o">.</span><span class="n">getmissing</span><span class="x">(</span><span class="n">model</span><span class="x">),</span> <span class="n">x</span><span class="x">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">2</span><span class="x">])</span>
<span class="k">if</span> <span class="n">preprocessed</span> <span class="k">isa</span> <span class="kt">Tuple</span>
    <span class="n">vn</span><span class="x">,</span> <span class="n">inds</span> <span class="o">=</span> <span class="n">preprocessed</span>
    <span class="n">temp_left</span> <span class="o">=</span> <span class="n">x</span><span class="x">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">2</span><span class="x">]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">dot_tilde</span><span class="x">(</span><span class="n">ctx</span><span class="x">,</span> <span class="n">sampler</span><span class="x">,</span> <span class="n">temp_right</span><span class="x">,</span> <span class="n">temp_left</span><span class="x">,</span> <span class="n">vn</span><span class="x">,</span> <span class="n">inds</span><span class="x">,</span> <span class="n">vi</span><span class="x">)</span>
    <span class="n">left</span> <span class="o">.=</span> <span class="n">out</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span>
    <span class="n">acclogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">out</span><span class="x">[</span><span class="mi">2</span><span class="x">])</span>
<span class="k">else</span>
    <span class="n">temp_left</span> <span class="o">=</span> <span class="n">preprocessed</span> <span class="c"># x[1:2]</span>
    <span class="n">lp</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">dot_tilde</span><span class="x">(</span><span class="n">ctx</span><span class="x">,</span> <span class="n">sampler</span><span class="x">,</span> <span class="n">temp_right</span><span class="x">,</span> <span class="n">temp_left</span><span class="x">,</span> <span class="n">vi</span><span class="x">)</span>
    <span class="n">acclogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">lp</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>
<p>The main difference in the expanded code between <code class="language-plaintext highlighter-rouge">L ~ R</code> and <code class="language-plaintext highlighter-rouge">@. L ~ R</code> is that the former doesn’t assume <code class="language-plaintext highlighter-rouge">L</code> to be defined, it can be a new Julia variable in the scope, while the latter assumes <code class="language-plaintext highlighter-rouge">L</code> already exists. <code class="language-plaintext highlighter-rouge">L</code> is also always input to the <code class="language-plaintext highlighter-rouge">dot_tilde</code> function but not the <code class="language-plaintext highlighter-rouge">tilde</code> function.</p>

<h2 id="replace_vi-replace_logpdf-and-replace_sampler"><code class="language-plaintext highlighter-rouge">replace_vi!</code>, <code class="language-plaintext highlighter-rouge">replace_logpdf!</code> and <code class="language-plaintext highlighter-rouge">replace_sampler!</code></h2>

<p>Using <code class="language-plaintext highlighter-rouge">@varinfo()</code> inside the model body will give the user access to the <code class="language-plaintext highlighter-rouge">vi::VarInfo</code> object used inside the model. The function <code class="language-plaintext highlighter-rouge">replace_vi!</code> therefore finds and replaces every use of <code class="language-plaintext highlighter-rouge">@varinfo()</code> with the handle to the <code class="language-plaintext highlighter-rouge">VarInfo</code> instance used inside the model. The <code class="language-plaintext highlighter-rouge">@logpdf()</code> macro will return <code class="language-plaintext highlighter-rouge">vi.logp[]</code> which is the accumumlated <code class="language-plaintext highlighter-rouge">log</code> probability that the model is computing. What this means can change depending on the context, <code class="language-plaintext highlighter-rouge">ctx</code>, used when running the model. Finally, <code class="language-plaintext highlighter-rouge">replace_sampler!</code> will replace <code class="language-plaintext highlighter-rouge">@sampler()</code> with the <code class="language-plaintext highlighter-rouge">sampler</code> input to the model.</p>

<h2 id="turingmodel"><code class="language-plaintext highlighter-rouge">Turing.Model</code></h2>

<p>Every <code class="language-plaintext highlighter-rouge">model::Model</code> can be called as a function with arguments:</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">vi::VarInfo</code>,</li>
  <li><code class="language-plaintext highlighter-rouge">spl::AbstractSampler</code>, and</li>
  <li><code class="language-plaintext highlighter-rouge">ctx::AbstractContext</code>.
<code class="language-plaintext highlighter-rouge">vi</code> is a data structure that stores information about random variables in <code class="language-plaintext highlighter-rouge">P</code>. <code class="language-plaintext highlighter-rouge">spl</code> includes the choice of the MCMC algorithm, e.g. Metropolis-Hastings, importance sampling or Hamiltonian Monte Carlo (HMC). <code class="language-plaintext highlighter-rouge">ctx</code> is used to modify the behaviour of the <code class="language-plaintext highlighter-rouge">logp</code> accumulator, accumulating different variants of it. For example, if <code class="language-plaintext highlighter-rouge">ctx isa LikelihoodContext</code>, only the log likelihood will be accumulated in <code class="language-plaintext highlighter-rouge">vi.logp[]</code>. By default, <code class="language-plaintext highlighter-rouge">ctx isa DefaultContext</code> which accumulates the log joint probability of <code class="language-plaintext highlighter-rouge">P</code> and <code class="language-plaintext highlighter-rouge">D</code>. The <code class="language-plaintext highlighter-rouge">Inference.tilde</code> and <code class="language-plaintext highlighter-rouge">Inference.dot_tilde</code> functions will do something different for different subtypes of <code class="language-plaintext highlighter-rouge">AbstractSampler</code> to facilitate the sampling process.</li>
</ol>

<p>The <code class="language-plaintext highlighter-rouge">Model</code> struct is defined as follows:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span><span class="nc"> Model</span><span class="x">{</span><span class="n">F</span><span class="x">,</span> <span class="n">Targs</span> <span class="o">&lt;:</span> <span class="kt">NamedTuple</span><span class="x">,</span> <span class="n">Tmodelgen</span><span class="x">,</span> <span class="n">Tmissings</span> <span class="o">&lt;:</span> <span class="kt">Val</span><span class="x">}</span>
    <span class="n">f</span><span class="o">::</span><span class="n">F</span>
    <span class="n">args</span><span class="o">::</span><span class="n">Targs</span>
    <span class="n">modelgen</span><span class="o">::</span><span class="n">Tmodelgen</span>
    <span class="n">missings</span><span class="o">::</span><span class="n">Tmissings</span>
<span class="k">end</span>
<span class="n">Model</span><span class="x">(</span><span class="n">f</span><span class="x">,</span> <span class="n">args</span><span class="o">::</span><span class="kt">NamedTuple</span><span class="x">,</span> <span class="n">modelgen</span><span class="x">)</span> <span class="o">=</span> <span class="n">Model</span><span class="x">(</span><span class="n">f</span><span class="x">,</span> <span class="n">args</span><span class="x">,</span> <span class="n">modelgen</span><span class="x">,</span> <span class="n">getmissing</span><span class="x">(</span><span class="n">args</span><span class="x">))</span>
<span class="x">(</span><span class="n">model</span><span class="o">::</span><span class="n">Model</span><span class="x">)(</span><span class="n">vi</span><span class="x">)</span> <span class="o">=</span> <span class="n">model</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">SampleFromPrior</span><span class="x">())</span>
<span class="x">(</span><span class="n">model</span><span class="o">::</span><span class="n">Model</span><span class="x">)(</span><span class="n">vi</span><span class="x">,</span> <span class="n">spl</span><span class="x">)</span> <span class="o">=</span> <span class="n">model</span><span class="x">(</span><span class="n">vi</span><span class="x">,</span> <span class="n">spl</span><span class="x">,</span> <span class="n">DefaultContext</span><span class="x">())</span>
<span class="x">(</span><span class="n">model</span><span class="o">::</span><span class="n">Model</span><span class="x">)(</span><span class="n">args</span><span class="o">...</span><span class="x">;</span> <span class="n">kwargs</span><span class="o">...</span><span class="x">)</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">f</span><span class="x">(</span><span class="n">args</span><span class="o">...</span><span class="x">,</span> <span class="n">model</span><span class="x">;</span> <span class="n">kwargs</span><span class="o">...</span><span class="x">)</span>
</code></pre></div></div>
<p><code class="language-plaintext highlighter-rouge">model.f</code> is an internal function that is called when <code class="language-plaintext highlighter-rouge">model</code> is called, where <code class="language-plaintext highlighter-rouge">model::Model</code>. When <code class="language-plaintext highlighter-rouge">model</code> is called, <code class="language-plaintext highlighter-rouge">model</code> itself is passed as an argument to <code class="language-plaintext highlighter-rouge">model.f</code> because we need to access <code class="language-plaintext highlighter-rouge">model.args</code> among other things inside <code class="language-plaintext highlighter-rouge">f</code>. <code class="language-plaintext highlighter-rouge">model.args</code> is a <code class="language-plaintext highlighter-rouge">NamedTuple</code> of all the arguments that were passed to the model generating function when constructing an instance of <code class="language-plaintext highlighter-rouge">Model</code>. <code class="language-plaintext highlighter-rouge">modelgen</code> is the instance of <code class="language-plaintext highlighter-rouge">ModelGen</code> that was used to construct <code class="language-plaintext highlighter-rouge">model</code>. <code class="language-plaintext highlighter-rouge">missings</code> is an instance of <code class="language-plaintext highlighter-rouge">Val</code>, e.g. <code class="language-plaintext highlighter-rouge">Val{(:a, :b)}()</code>. <code class="language-plaintext highlighter-rouge">getmissings</code> returns a <code class="language-plaintext highlighter-rouge">Val</code> instance of all the symbols in <code class="language-plaintext highlighter-rouge">args</code> with a value <code class="language-plaintext highlighter-rouge">missing</code>. This is the default definition of <code class="language-plaintext highlighter-rouge">missings</code>. All variables in <code class="language-plaintext highlighter-rouge">missings</code> are treated as random variables rather than observations.</p>

<p>In some non-traditional use-cases, <code class="language-plaintext highlighter-rouge">missings</code> is defined differently, e.g. when computing the log joint probability of the random variables and only some observations simultaneously, possibly conditioned on the remaining observations. An example using the model above is <code class="language-plaintext highlighter-rouge">logprob"x = rand(3), p = rand(2) | model = gauss, y = nothing"</code>. To evaluate this, the model argument <code class="language-plaintext highlighter-rouge">x</code> on the LHS of <code class="language-plaintext highlighter-rouge">|</code> is treated as a random variable leading to a call to the <code class="language-plaintext highlighter-rouge">assume</code> or <code class="language-plaintext highlighter-rouge">dot_assume</code> function in place of the <code class="language-plaintext highlighter-rouge">~</code> or <code class="language-plaintext highlighter-rouge">.~</code> expressions, respectively. The model is then run in the <code class="language-plaintext highlighter-rouge">PriorContext</code> which ignores the <code class="language-plaintext highlighter-rouge">observe</code> and <code class="language-plaintext highlighter-rouge">dot_observe</code> functions and only runs the <code class="language-plaintext highlighter-rouge">assume</code> and <code class="language-plaintext highlighter-rouge">dot_assume</code> ones. This returns the correct log probability. The reason why a model input argument, such as <code class="language-plaintext highlighter-rouge">x</code>, cannot be initialized to <code class="language-plaintext highlighter-rouge">missing</code> when on the LHS of <code class="language-plaintext highlighter-rouge">|</code> is somewhat subtle. In the model body before calling <code class="language-plaintext highlighter-rouge">~</code>, sometimes there would be a call to <code class="language-plaintext highlighter-rouge">length(x)</code> iterating over the elements of <code class="language-plaintext highlighter-rouge">x</code> in a loop calling <code class="language-plaintext highlighter-rouge">~</code> on each element of <code class="language-plaintext highlighter-rouge">x</code>. If <code class="language-plaintext highlighter-rouge">x</code> is initialized to <code class="language-plaintext highlighter-rouge">missing</code>, this will error because <code class="language-plaintext highlighter-rouge">length(missing)</code> is not defined. Moreover, it is not intuitive to require the user to handle the <code class="language-plaintext highlighter-rouge">x === missing</code> case because the user never assigned <code class="language-plaintext highlighter-rouge">x</code> to be <code class="language-plaintext highlighter-rouge">missing</code> in the first place, <code class="language-plaintext highlighter-rouge">missing</code> is merely an implementation detail in this case that the users need not concern themselves with. Therefore in this case, it makes sense to de-couple the <code class="language-plaintext highlighter-rouge">missings</code> field from the values of the arguments.</p>

<h2 id="build_output"><code class="language-plaintext highlighter-rouge">build_output</code></h2>

<p>Now that we have all the information we need in the <code class="language-plaintext highlighter-rouge">@model</code> macro, we can start building the model generator function. The model generator function <code class="language-plaintext highlighter-rouge">gauss</code> will be defined as:</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> outer_function</span><span class="x">(;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">missing</span><span class="x">,</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mf">1.0</span><span class="x">,</span>
    <span class="n">TV</span><span class="o">::</span><span class="kt">Type</span><span class="x">{</span><span class="o">&lt;:</span><span class="kt">AbstractVector</span><span class="x">}</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">},</span>
<span class="x">)</span>
    <span class="k">return</span> <span class="n">outer_function</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">,</span> <span class="n">TV</span><span class="x">)</span>
<span class="k">end</span>
<span class="k">function</span><span class="nf"> outer_function</span><span class="x">(</span>
    <span class="n">x</span> <span class="o">=</span> <span class="nb">missing</span><span class="x">,</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mf">1.0</span><span class="x">,</span>
    <span class="n">TV</span><span class="o">::</span><span class="kt">Type</span><span class="x">{</span><span class="o">&lt;:</span><span class="kt">AbstractVector</span><span class="x">}</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">},</span>
<span class="x">)</span>
    <span class="k">function</span><span class="nf"> inner_function</span><span class="x">(</span><span class="n">vi</span><span class="o">::</span><span class="n">Turing</span><span class="o">.</span><span class="n">VarInfo</span><span class="x">,</span> <span class="n">sampler</span><span class="o">::</span><span class="n">Turing</span><span class="o">.</span><span class="n">AbstractSampler</span><span class="x">,</span> <span class="n">ctx</span><span class="o">::</span><span class="n">AbstractContext</span><span class="x">,</span> <span class="n">model</span><span class="x">)</span>
        <span class="o">...</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Model</span><span class="x">(</span>
        <span class="n">inner_function</span><span class="x">,</span>
        <span class="x">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="x">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="x">,</span> <span class="n">TV</span> <span class="o">=</span> <span class="n">TV</span><span class="x">),</span>
        <span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="n">ModelGen</span><span class="x">{(</span><span class="o">:</span><span class="n">x</span><span class="x">,</span> <span class="o">:</span><span class="n">y</span><span class="x">,</span> <span class="o">:</span><span class="n">TV</span><span class="x">)}(</span>
            <span class="n">outer_function</span><span class="x">,</span>
            <span class="x">(</span><span class="n">x</span> <span class="o">=</span> <span class="nb">missing</span><span class="x">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.0</span><span class="x">,</span> <span class="n">TV</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}),</span>
        <span class="x">),</span>
    <span class="x">)</span>
<span class="k">end</span>
<span class="n">gauss</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="n">ModelGen</span><span class="x">{(</span><span class="o">:</span><span class="n">x</span><span class="x">,</span> <span class="o">:</span><span class="n">y</span><span class="x">,</span> <span class="o">:</span><span class="n">TV</span><span class="x">)}(</span>
            <span class="n">outer_function</span><span class="x">,</span>
            <span class="x">(</span><span class="n">x</span> <span class="o">=</span> <span class="nb">missing</span><span class="x">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.0</span><span class="x">,</span> <span class="n">TV</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}),</span>
        <span class="x">)</span>
</code></pre></div></div>
<p>The above 2 methods enable constructing the model using positional or keyword arguments. The second argument to the <code class="language-plaintext highlighter-rouge">Turing.Model</code> constructor is the expression called <code class="language-plaintext highlighter-rouge">args_nt</code> stored in <code class="language-plaintext highlighter-rouge">model_info</code>. The second argument to the <code class="language-plaintext highlighter-rouge">ModelGen</code> constructor inside <code class="language-plaintext highlighter-rouge">outer_function</code> and outside is the expression called <code class="language-plaintext highlighter-rouge">defaults_nt</code> stored in <code class="language-plaintext highlighter-rouge">model_info</code>. The body of the <code class="language-plaintext highlighter-rouge">inner_function</code> is explained below.</p>

<h2 id="inner_function"><code class="language-plaintext highlighter-rouge">inner_function</code></h2>

<p>The main method of <code class="language-plaintext highlighter-rouge">inner_function</code> does some pre-processing defining all the input variables from the model definition, <code class="language-plaintext highlighter-rouge">x</code>, <code class="language-plaintext highlighter-rouge">y</code> and <code class="language-plaintext highlighter-rouge">TV</code> in the example above. Then the rest of the model body is run as normal Julia code with the <code class="language-plaintext highlighter-rouge">L ~ R</code> and <code class="language-plaintext highlighter-rouge">@. L ~ R</code> lines replaced with the calls to <code class="language-plaintext highlighter-rouge">Inference.tilde</code> and <code class="language-plaintext highlighter-rouge">Inference.dot_tilde</code> respectively as shown earlier.</p>
<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> inner_function</span><span class="x">(</span><span class="n">vi</span><span class="o">::</span><span class="n">Turing</span><span class="o">.</span><span class="n">VarInfo</span><span class="x">,</span> <span class="n">sampler</span><span class="o">::</span><span class="n">Turing</span><span class="o">.</span><span class="n">AbstractSampler</span><span class="x">,</span> <span class="n">ctx</span><span class="o">::</span><span class="n">AbstractContext</span><span class="x">,</span> <span class="n">model</span><span class="x">)</span>
    <span class="n">temp_x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">x</span>
    <span class="n">xT</span> <span class="o">=</span> <span class="n">typeof</span><span class="x">(</span><span class="n">temp_x</span><span class="x">)</span>
    <span class="k">if</span> <span class="n">temp_x</span> <span class="k">isa</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="n">FloatOrArrayType</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="n">get_matching_type</span><span class="x">(</span><span class="n">sampler</span><span class="x">,</span> <span class="n">vi</span><span class="x">,</span> <span class="n">temp_x</span><span class="x">)</span>
    <span class="k">elseif</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="n">hasmissing</span><span class="x">(</span><span class="n">xT</span><span class="x">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Core</span><span class="o">.</span><span class="n">get_matching_type</span><span class="x">(</span><span class="n">sampler</span><span class="x">,</span> <span class="n">vi</span><span class="x">,</span> <span class="n">xT</span><span class="x">)(</span><span class="n">temp_x</span><span class="x">)</span>
    <span class="k">else</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">temp_x</span>
    <span class="k">end</span>

    <span class="o">...</span> <span class="c"># The code above is repeated for the other 2 variables, y and TV</span>

    <span class="c"># Reset the `logp` accumulator</span>
    <span class="n">resetlogp!</span><span class="x">(</span><span class="n">vi</span><span class="x">)</span>

    <span class="o">...</span> <span class="c"># Main model body</span>
<span class="k">end</span>
</code></pre></div></div>
<p>As one can see above, <code class="language-plaintext highlighter-rouge">x</code>, <code class="language-plaintext highlighter-rouge">y</code> and <code class="language-plaintext highlighter-rouge">TV</code> are defined in the method body using an <code class="language-plaintext highlighter-rouge">if</code>-block followed by the rest of the code. The first branch of this <code class="language-plaintext highlighter-rouge">if</code>-block is run if the variable is a number or array type, such as <code class="language-plaintext highlighter-rouge">TV = Vector{Float64}</code>. One of the purposes of <code class="language-plaintext highlighter-rouge">get_matching_type</code> is to check if <code class="language-plaintext highlighter-rouge">sampler</code> requires automatic differentiation, and to modify <code class="language-plaintext highlighter-rouge">TV</code> accordingly. For example, when using <code class="language-plaintext highlighter-rouge">ForwardDiff</code> for automatic differentiation, <code class="language-plaintext highlighter-rouge">TV</code> will be defined as some concrete subtype of <code class="language-plaintext highlighter-rouge">Vector{&lt;:ForwardDiff.Dual}</code>. This same function is also used to replace <code class="language-plaintext highlighter-rouge">Array</code> with <code class="language-plaintext highlighter-rouge">Libtask.TArray</code> types when a particle sampler is used.</p>

<p>The second branch of the <code class="language-plaintext highlighter-rouge">if</code>-block is to handle partially missing data converting the type of the input vector to another type befitting of the sampler used, whether it is for automatic differentiation or for particle samplers. Finally, the third branch is the one that will be run for <code class="language-plaintext highlighter-rouge">x</code> and <code class="language-plaintext highlighter-rouge">y</code> above simply assigning these names to <code class="language-plaintext highlighter-rouge">model.args.x</code> and <code class="language-plaintext highlighter-rouge">model.args.y</code> respectively. The main model body is then the same model body passed in by the user after replacing <code class="language-plaintext highlighter-rouge">L ~ R</code>, <code class="language-plaintext highlighter-rouge">@. L ~ R</code>, <code class="language-plaintext highlighter-rouge">@varinfo()</code> and <code class="language-plaintext highlighter-rouge">@logpdf()</code> as explained eariler.</p>

<h1 id="varname"><code class="language-plaintext highlighter-rouge">VarName</code></h1>

<p>In order to track random variables in the sampling process, <code class="language-plaintext highlighter-rouge">Turing</code> uses the struct <code class="language-plaintext highlighter-rouge">VarName{sym}</code> which acts as a random variable identifier generated at runtime. The <code class="language-plaintext highlighter-rouge">VarName</code> of a random variable is generated from the expression on the LHS of a <code class="language-plaintext highlighter-rouge">~</code> statement when the symbol on the LHS is in <code class="language-plaintext highlighter-rouge">P</code>. Every <code class="language-plaintext highlighter-rouge">vn::VarName{sym}</code> has a symbol <code class="language-plaintext highlighter-rouge">sym</code> which is the symbol of the Julia variable in the model that the random variable belongs to. For example, <code class="language-plaintext highlighter-rouge">x[1] ~ Normal()</code> will generate an instance of <code class="language-plaintext highlighter-rouge">VarName{:x}</code> assuming <code class="language-plaintext highlighter-rouge">x</code> is in <code class="language-plaintext highlighter-rouge">P</code>. Every <code class="language-plaintext highlighter-rouge">vn::VarName</code> also has a field <code class="language-plaintext highlighter-rouge">indexing</code> which stores the indices requires to access the random variable from the Julia variable indicated by <code class="language-plaintext highlighter-rouge">sym</code>. For example, <code class="language-plaintext highlighter-rouge">x[1] ~ Normal()</code> will generate a <code class="language-plaintext highlighter-rouge">vn::VarName{:x}</code> with <code class="language-plaintext highlighter-rouge">vn.indexing == "[1]"</code>. <code class="language-plaintext highlighter-rouge">VarName</code> also supports hierarchical arrays and range indexing. Some more examples:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">x[1] ~ Normal()</code> will generate a <code class="language-plaintext highlighter-rouge">VarName{:x}</code> with <code class="language-plaintext highlighter-rouge">indexing == "[1]"</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">x[:,1] ~ MvNormal(zeros(2))</code> will generate a <code class="language-plaintext highlighter-rouge">VarName{:x}</code> with <code class="language-plaintext highlighter-rouge">indexing == "[Colon(),1]"</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">x[:,1][2] ~ Normal()</code> will generate a <code class="language-plaintext highlighter-rouge">VarName{:x}</code> with <code class="language-plaintext highlighter-rouge">indexing == "[Colon(),1][2]"</code>.</li>
</ul>

<h1 id="varinfo"><code class="language-plaintext highlighter-rouge">VarInfo</code></h1>

<h2 id="overview-1">Overview</h2>

<p><code class="language-plaintext highlighter-rouge">VarInfo</code> is the data structure in <code class="language-plaintext highlighter-rouge">Turing</code> that facilitates tracking random variables and certain metadata about them that are required for sampling. For instance, the distribution of every random variable is stored in <code class="language-plaintext highlighter-rouge">VarInfo</code> because we need to know the support of every random variable when sampling using HMC for example. Random variables whose distributions have a constrained support are transformed using a bijector from <a href="https://github.com/TuringLang/Bijectors.jl">Bijectors.jl</a> so that the sampling happens in the unconstrained space. Different samplers require different metadata about the random variables.</p>

<p>The definition of <code class="language-plaintext highlighter-rouge">VarInfo</code> in <code class="language-plaintext highlighter-rouge">Turing</code> is:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>struct VarInfo{Tmeta, Tlogp} &lt;: AbstractVarInfo
    metadata::Tmeta
    logp::Base.RefValue{Tlogp}
    num_produce::Base.RefValue{Int}
end
</code></pre></div></div>
<p>Based on the type of <code class="language-plaintext highlighter-rouge">metadata</code>, the <code class="language-plaintext highlighter-rouge">VarInfo</code> is either aliased <code class="language-plaintext highlighter-rouge">UntypedVarInfo</code> or <code class="language-plaintext highlighter-rouge">TypedVarInfo</code>. <code class="language-plaintext highlighter-rouge">metadata</code> can be either a subtype of the union type <code class="language-plaintext highlighter-rouge">Metadata</code> or a <code class="language-plaintext highlighter-rouge">NamedTuple</code> of multiple such subtypes. Let <code class="language-plaintext highlighter-rouge">vi</code> be an instance of <code class="language-plaintext highlighter-rouge">VarInfo</code>. If <code class="language-plaintext highlighter-rouge">vi isa VarInfo{&lt;:Metadata}</code>, then it is called an <code class="language-plaintext highlighter-rouge">UntypedVarInfo</code>. If <code class="language-plaintext highlighter-rouge">vi isa VarInfo{&lt;:NamedTuple}</code>, then <code class="language-plaintext highlighter-rouge">vi.metadata</code> would be a <code class="language-plaintext highlighter-rouge">NamedTuple</code> mapping each symbol in <code class="language-plaintext highlighter-rouge">P</code> to an instance of <code class="language-plaintext highlighter-rouge">Metadata</code>. <code class="language-plaintext highlighter-rouge">vi</code> would then be called a <code class="language-plaintext highlighter-rouge">TypedVarInfo</code>. The other fields of <code class="language-plaintext highlighter-rouge">VarInfo</code> include <code class="language-plaintext highlighter-rouge">logp</code> which is used to accumulate the log probability or log probability density of the variables in <code class="language-plaintext highlighter-rouge">P</code> and <code class="language-plaintext highlighter-rouge">D</code>. <code class="language-plaintext highlighter-rouge">num_produce</code> keeps track of how many observations have been made in the model so far. This is incremented when running a <code class="language-plaintext highlighter-rouge">~</code> statement when the symbol on the LHS is in <code class="language-plaintext highlighter-rouge">D</code>.</p>

<h2 id="metadata"><code class="language-plaintext highlighter-rouge">Metadata</code></h2>

<p>The <code class="language-plaintext highlighter-rouge">Metadata</code> struct stores some metadata about the random variables sampled. This helps
query certain information about a variable such as: its distribution, which samplers
sample this variable, its value and whether this value is transformed to real space or
not. Let <code class="language-plaintext highlighter-rouge">md</code> be an instance of <code class="language-plaintext highlighter-rouge">Metadata</code>:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">md.vns</code> is the vector of all <code class="language-plaintext highlighter-rouge">VarName</code> instances. Let <code class="language-plaintext highlighter-rouge">vn</code> be an arbitrary element of <code class="language-plaintext highlighter-rouge">md.vns</code></li>
  <li><code class="language-plaintext highlighter-rouge">md.idcs</code> is the dictionary that maps each <code class="language-plaintext highlighter-rouge">VarName</code> instance to its index in
 <code class="language-plaintext highlighter-rouge">md.vns</code>, <code class="language-plaintext highlighter-rouge">md.ranges</code>, <code class="language-plaintext highlighter-rouge">md.dists</code>, <code class="language-plaintext highlighter-rouge">md.orders</code> and <code class="language-plaintext highlighter-rouge">md.flags</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">md.vns[md.idcs[vn]] == vn</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">md.dists[md.idcs[vn]]</code> is the distribution of <code class="language-plaintext highlighter-rouge">vn</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">md.gids[md.idcs[vn]]</code> is the set of algorithms used to sample <code class="language-plaintext highlighter-rouge">vn</code>. This is used in
 the Gibbs sampling process.</li>
  <li><code class="language-plaintext highlighter-rouge">md.orders[md.idcs[vn]]</code> is the number of <code class="language-plaintext highlighter-rouge">observe</code> statements before <code class="language-plaintext highlighter-rouge">vn</code> is sampled.</li>
  <li><code class="language-plaintext highlighter-rouge">md.ranges[md.idcs[vn]]</code> is the index range of <code class="language-plaintext highlighter-rouge">vn</code> in <code class="language-plaintext highlighter-rouge">md.vals</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">md.vals[md.ranges[md.idcs[vn]]]</code> is the linearized vector of values of corresponding to <code class="language-plaintext highlighter-rouge">vn</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">md.flags</code> is a dictionary of true/false flags. <code class="language-plaintext highlighter-rouge">md.flags[flag][md.idcs[vn]]</code> is the
 value of <code class="language-plaintext highlighter-rouge">flag</code> corresponding to <code class="language-plaintext highlighter-rouge">vn</code>.</li>
</ul>

<p>Note that in order to make <code class="language-plaintext highlighter-rouge">md::Metadata</code> type stable, all the <code class="language-plaintext highlighter-rouge">md.vns</code> must have the same symbol and distribution type. However, one can have a single Julia variable, e.g. <code class="language-plaintext highlighter-rouge">x</code>, that is a matrix or a hierarchical array sampled in partitions, e.g. <code class="language-plaintext highlighter-rouge">x[1][:] ~ MvNormal(zeros(2), 1.0); x[2][:] ~ MvNormal(ones(2), 1.0)</code>. The symbol <code class="language-plaintext highlighter-rouge">x</code> can still be managed by a single <code class="language-plaintext highlighter-rouge">md::Metadata</code> without hurting the type stability since all the distributions on the RHS of <code class="language-plaintext highlighter-rouge">~</code> are of the same type.</p>

<p>However, in <code class="language-plaintext highlighter-rouge">Turing</code> models one cannot have this restriction, so we must use a type unstable <code class="language-plaintext highlighter-rouge">Metadata</code> if we want to use one <code class="language-plaintext highlighter-rouge">Metadata</code> instance for the whole model. This is what <code class="language-plaintext highlighter-rouge">UntypedVarInfo</code> does. A type unstable <code class="language-plaintext highlighter-rouge">Metadata</code> will still work but will have inferior performance.</p>

<p>To strike a balance between flexibility and performance when constructing the <code class="language-plaintext highlighter-rouge">spl::Sampler</code> instance, the model is first run by sampling the parameters in <code class="language-plaintext highlighter-rouge">P</code> from their priors using an <code class="language-plaintext highlighter-rouge">UntypedVarInfo</code>, i.e. a type unstable <code class="language-plaintext highlighter-rouge">Metadata</code> is used for all the variables. Then once all the symbols and distribution types have been identified, a <code class="language-plaintext highlighter-rouge">vi::TypedVarInfo</code> is constructed where <code class="language-plaintext highlighter-rouge">vi.metadata</code> is a <code class="language-plaintext highlighter-rouge">NamedTuple</code> mapping each symbol in <code class="language-plaintext highlighter-rouge">P</code> to a specialized instance of <code class="language-plaintext highlighter-rouge">Metadata</code>. So as long as each symbol in <code class="language-plaintext highlighter-rouge">P</code> is sampled from only one type of distributions, <code class="language-plaintext highlighter-rouge">vi::TypedVarInfo</code> will have fully concretely typed fields which brings out the peak performance of Julia.</p>
