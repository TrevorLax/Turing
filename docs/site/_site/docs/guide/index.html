<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.13.0 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Guide - Turing.jl</title>
<meta name="description" content="">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Turing.jl">
<meta property="og:title" content="Guide">
<meta property="og:url" content="http://localhost:4000/docs/guide/">


  <meta property="og:description" content="">







  <meta property="article:published_time" content="2019-06-08T21:56:58-04:00">






<link rel="canonical" href="http://localhost:4000/docs/guide/">













<!-- end _includes/seo.html -->



<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">

<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Turing.jl Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/Documenter.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->


    
      <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Turing.jl </a>
        <!-- Turing.jl -->
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/" >Home</a>
            </li><li class="masthead__menu-item">
              <a href="/docs/" >Documentation</a>
            </li><li class="masthead__menu-item">
              <a href="/tutorials/" >Tutorials</a>
            </li><li class="masthead__menu-item">
              <a href="https://github.com/TuringLang/Turing.jl" >GitHub</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    

    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">Using Turing</span>
        

        
        <ul>
          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/get-started/" class="">Getting Started</a></li>
            </div>

          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/quick-start/" class="">Quick Start</a></li>
            </div>

          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/guide/" class="active">Guide</a></li>
            </div>

          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/advanced/" class="">Advanced Usage</a></li>
            </div>

          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/autodiff/" class="">Automatic Differentiation</a></li>
            </div>

          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/dynamichmc/" class="">Using DynamicHMC</a></li>
            </div>

          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/sampler-viz/" class="">Sampler Visualization</a></li>
            </div>

          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Library</span>
        

        
        <ul>
          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/library/" class="">Public</a></li>
            </div>

          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Contributing</span>
        

        
        <ul>
          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/contributing/" class="">How to Contribute</a></li>
            </div>

          
            
            

            
            

            <div class="sidebar-link">
            <li><a href="/docs/style-guide/" class="">Style Guide</a></li>
            </div>

          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Guide">
    <meta itemprop="description" content="">
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Guide
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-list-ul"></i> Contents</h4></header>
              <ul class="toc__menu">
  <li><a href="#basics">Basics</a>
    <ul>
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#simple-gaussian-demo">Simple Gaussian Demo</a></li>
      <li><a href="#modelling-syntax-explained">Modelling Syntax Explained</a></li>
      <li><a href="#sampling-multiple-chains">Sampling Multiple Chains</a></li>
      <li><a href="#sampling-from-an-unconditional-distribution-the-prior">Sampling from an Unconditional Distribution (The Prior)</a></li>
      <li><a href="#sampling-from-a-conditional-distribution-the-posterior">Sampling from a Conditional Distribution (The Posterior)</a>
        <ul>
          <li><a href="#using-missing">Using Missing</a></li>
          <li><a href="#using-argument-defaults">Using Argument Defaults</a></li>
          <li><a href="#what-to-use-as-a-default-value">What to Use as a Default Value</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#beyond-the-basics">Beyond the Basics</a>
    <ul>
      <li><a href="#compositional-sampling-using-gibbs">Compositional Sampling Using Gibbs</a></li>
      <li><a href="#working-with-mcmcchainsjl">Working with MCMCChains.jl</a></li>
      <li><a href="#working-with-libtaskjl">Working with Libtask.jl</a></li>
      <li><a href="#changing-default-settings">Changing Default Settings</a>
        <ul>
          <li><a href="#ad-chunk-size">AD Chunk Size</a></li>
          <li><a href="#ad-backend">AD Backend</a></li>
          <li><a href="#progress-meter">Progress Meter</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
            </nav>
          </aside>
        
        <p><a id="Basics-1"></a></p>

<h2 id="basics">Basics</h2>

<p><a id="Introduction-1"></a></p>

<h3 id="introduction">Introduction</h3>

<p>A probabilistic program is Julia code wrapped in a <code class="highlighter-rouge">@model</code> macro. It can use arbitrary Julia code, but to ensure correctness of inference it should not have external effects or modify global state. Stack-allocated variables are safe, but mutable heap-allocated objects may lead to subtle bugs when using task copying. To help avoid those we provide a Turing-safe datatype <code class="highlighter-rouge">TArray</code> that can be used to create mutable arrays in Turing programs.</p>

<p>To specify distributions of random variables, Turing programs should use the <code class="highlighter-rouge">~</code> notation:</p>

<p><code class="highlighter-rouge">x ~ distr</code> where <code class="highlighter-rouge">x</code> is a symbol and <code class="highlighter-rouge">distr</code> is a distribution. If <code class="highlighter-rouge">x</code> is undefined in the model function, inside the probabilistic program, this puts a random variable named <code class="highlighter-rouge">x</code>, distributed according to <code class="highlighter-rouge">distr</code>, in the current scope. <code class="highlighter-rouge">distr</code> can be a value of any type that implements <code class="highlighter-rouge">rand(distr)</code>, which samples a value from the distribution <code class="highlighter-rouge">distr</code>. If <code class="highlighter-rouge">x</code> is defined, this is used for conditioning in a style similar to <a href="https://probprog.github.io/anglican/index.html">Anglican</a> (another PPL). In this case, <code class="highlighter-rouge">x</code> is an observed value, assumed to have been drawn from the distribution <code class="highlighter-rouge">distr</code>. The likelihood is computed using <code class="highlighter-rouge">logpdf(distr,y)</code>. The observe statements should be arranged so that every possible run traverses all of them in exactly the same order. This is equivalent to demanding that they are not placed inside stochastic control flow.</p>

<p>Available inference methods include  Importance Sampling (IS), Sequential Monte Carlo (SMC), Particle Gibbs (PG), Hamiltonian Monte Carlo (HMC), Hamiltonian Monte Carlo with Dual Averaging (HMCDA) and The No-U-Turn Sampler (NUTS).</p>

<p><a id="Simple-Gaussian-Demo-1"></a></p>

<h3 id="simple-gaussian-demo">Simple Gaussian Demo</h3>

<p>Below is a simple Gaussian demo illustrate the basic usage of Turing.jl.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Import packages.</span>
<span class="k">using</span> <span class="n">Turing</span>
<span class="k">using</span> <span class="n">StatsPlots</span>

<span class="c"># Define a simple Normal model with unknown mean and variance.</span>
<span class="nd">@model</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
  <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Note: As a sanity check, the expectation of <code class="highlighter-rouge">s</code> is 49/24 (2.04166666…) and the expectation of <code class="highlighter-rouge">m</code> is 7/6 (1.16666666…).</p>

<p>We can perform inference by using the <code class="highlighter-rouge">sample</code> function, the first argument of which is our probabalistic program and the second of which is a sampler. More information on each sampler is located in the <a href="/docs/library/">API</a>.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#  Run sampler, collect results.</span>
<span class="n">c1</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">SMC</span><span class="x">(</span><span class="mi">1000</span><span class="x">))</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">PG</span><span class="x">(</span><span class="mi">10</span><span class="x">,</span><span class="mi">1000</span><span class="x">))</span>
<span class="n">c3</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">HMC</span><span class="x">(</span><span class="mi">1000</span><span class="x">,</span> <span class="mf">0.1</span><span class="x">,</span> <span class="mi">5</span><span class="x">))</span>
<span class="n">c4</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">Gibbs</span><span class="x">(</span><span class="mi">1000</span><span class="x">,</span> <span class="n">PG</span><span class="x">(</span><span class="mi">10</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="o">:</span><span class="n">m</span><span class="x">),</span> <span class="n">HMC</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mf">0.1</span><span class="x">,</span> <span class="mi">5</span><span class="x">,</span> <span class="o">:</span><span class="n">s</span><span class="x">)))</span>
<span class="n">c5</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">HMCDA</span><span class="x">(</span><span class="mi">1000</span><span class="x">,</span> <span class="mf">0.15</span><span class="x">,</span> <span class="mf">0.65</span><span class="x">))</span>
<span class="n">c6</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="n">NUTS</span><span class="x">(</span><span class="mi">1000</span><span class="x">,</span>  <span class="mf">0.65</span><span class="x">))</span>
</code></pre></div></div>

<p>The <code class="highlighter-rouge">MCMCChains</code> module (which is re-exported by Turing) provides plotting tools for the <code class="highlighter-rouge">Chain</code> objects returned by a <code class="highlighter-rouge">sample</code> function. See the <a href="https://github.com/TuringLang/MCMCChains.jl">MCMCChains</a> repository for more information on the suite of tools available for diagnosing MCMC chains.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Summarise results</span>
<span class="n">describe</span><span class="x">(</span><span class="n">c3</span><span class="x">)</span>

<span class="c"># Plot results</span>
<span class="n">plot</span><span class="x">(</span><span class="n">c3</span><span class="x">)</span>
<span class="n">savefig</span><span class="x">(</span><span class="s">"gdemo-plot.png"</span><span class="x">)</span>
</code></pre></div></div>

<p>The arguments for each sampler are:</p>

<ul>
  <li>SMC: number of particles.</li>
  <li>PG: number of particles, number of iterations.</li>
  <li>HMC: number of samples, leapfrog step size, leapfrog step numbers.</li>
  <li>Gibbs: number of samples, component sampler 1, component sampler 2, …</li>
  <li>HMCDA: number of samples, total leapfrog length, target accept ratio.</li>
  <li>NUTS: number of samples, target accept ratio.</li>
</ul>

<p>For detailed information on the samplers, please review Turing.jl’s <a href="/docs/library/">API</a> documentation.</p>

<p><a id="Modelling-Syntax-Explained-1"></a></p>

<h3 id="modelling-syntax-explained">Modelling Syntax Explained</h3>

<p>Using this syntax, a probabilistic model is defined in Turing. The model function generated by Turing can then be used to condition the model onto data. Subsequently, the sample function can be used to generate samples from the posterior distribution.</p>

<p>In the following example, the defined model is conditioned to the date (arg<em>1 = 1, arg</em>2 = 2) by passing (1, 2) to the model function.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">model_name</span><span class="x">(</span><span class="n">arg_1</span><span class="x">,</span> <span class="n">arg_2</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="o">...</span>
<span class="k">end</span>
</code></pre></div></div>

<p>The conditioned model can then be passed onto the sample function to run posterior inference.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_func</span> <span class="o">=</span> <span class="n">model_name</span><span class="x">(</span><span class="mi">1</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
<span class="n">chn</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model_func</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="o">..</span><span class="x">))</span> <span class="c"># Perform inference by sampling using HMC.</span>
</code></pre></div></div>

<p>The returned chain contains samples of the variables in the model.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">var_1</span> <span class="o">=</span> <span class="n">mean</span><span class="x">(</span><span class="n">chn</span><span class="x">[</span><span class="o">:</span><span class="n">var_1</span><span class="x">])</span> <span class="c"># Taking the mean of a variable named var_1.</span>
</code></pre></div></div>

<p>The key (<code class="highlighter-rouge">:var_1</code>) can be a <code class="highlighter-rouge">Symbol</code> or a <code class="highlighter-rouge">String</code>. For example, to fetch <code class="highlighter-rouge">x[1]</code>, one can use <code class="highlighter-rouge">chn[Symbol("x[1]")</code> or <code class="highlighter-rouge">chn["x[1]"]</code>.</p>

<p>The benefit of using a <code class="highlighter-rouge">Symbol</code> to index allows you to retrieve all the parameters associated with that symbol. As an example, if you have the parameters <code class="highlighter-rouge">"x[1]"</code>, <code class="highlighter-rouge">"x[2]"</code>, and <code class="highlighter-rouge">"x[3]"</code>, calling <code class="highlighter-rouge">chn[:x]</code> will return a new chain with only <code class="highlighter-rouge">"x[1]"</code>, <code class="highlighter-rouge">"x[2]"</code>, and <code class="highlighter-rouge">"x[3]"</code>.</p>

<p>Turing does not have a declarative form. More generally, the order in which you place the lines of a <code class="highlighter-rouge">@model</code> macro matters. For example, the following example works:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Define a simple Normal model with unknown mean and variance.</span>
<span class="nd">@model</span> <span class="n">model_function</span><span class="x">(</span><span class="n">y</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="n">s</span> <span class="o">~</span> <span class="n">Poisson</span><span class="x">(</span><span class="mi">1</span><span class="x">)</span>
  <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">s</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
  <span class="k">return</span> <span class="n">y</span>
<span class="k">end</span>

<span class="n">sample</span><span class="x">(</span><span class="n">model_function</span><span class="x">(</span><span class="mi">10</span><span class="x">),</span> <span class="n">SMC</span><span class="x">(</span><span class="mi">100</span><span class="x">))</span>
</code></pre></div></div>

<p>But if we switch the <code class="highlighter-rouge">s ~ Poisson(1)</code> and <code class="highlighter-rouge">y ~ Normal(s, 1)</code> lines, the model will no longer sample correctly:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Define a simple Normal model with unknown mean and variance.</span>
<span class="nd">@model</span> <span class="n">model_function</span><span class="x">(</span><span class="n">y</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">s</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
  <span class="n">s</span> <span class="o">~</span> <span class="n">Poisson</span><span class="x">(</span><span class="mi">1</span><span class="x">)</span>
  <span class="k">return</span> <span class="n">y</span>
<span class="k">end</span>

<span class="n">sample</span><span class="x">(</span><span class="n">model_function</span><span class="x">(</span><span class="mi">10</span><span class="x">),</span> <span class="n">SMC</span><span class="x">(</span><span class="mi">100</span><span class="x">))</span>
</code></pre></div></div>

<p><a id="Sampling-Multiple-Chains-1"></a></p>

<h3 id="sampling-multiple-chains">Sampling Multiple Chains</h3>

<p>If you wish to run multiple chains, you can do so with the <code class="highlighter-rouge">mapreduce</code> function:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Replace num_chains below with however many chains you wish to sample.</span>
<span class="n">chains</span> <span class="o">=</span> <span class="n">mapreduce</span><span class="x">(</span><span class="n">c</span> <span class="o">-&gt;</span> <span class="n">sample</span><span class="x">(</span><span class="n">model_fun</span><span class="x">,</span> <span class="n">sampler</span><span class="x">),</span> <span class="n">chainscat</span><span class="x">,</span> <span class="mi">1</span><span class="o">:</span><span class="n">num_chains</span><span class="x">)</span>
</code></pre></div></div>

<p>The <code class="highlighter-rouge">chains</code> variable now contains a <code class="highlighter-rouge">Chains</code> object which can be indexed by chain. To pull out the first chain from the <code class="highlighter-rouge">chains</code> object, use <code class="highlighter-rouge">chains[:,:,1]</code>.</p>

<p>Having multiple chains in the same object is valuable for evaluating convergence. Some diagnostic functions like <code class="highlighter-rouge">gelmandiag</code> require multiple chains.</p>

<p>Please note that Turing does not have native support for chains sampled in parallel.</p>

<p><a id="Sampling-from-an-Unconditional-Distribution-(The-Prior)-1"></a></p>

<h3 id="sampling-from-an-unconditional-distribution-the-prior">Sampling from an Unconditional Distribution (The Prior)</h3>

<p>Turing allows you to sample from a declared model’s prior by calling the model without specifying inputs or a sampler. In the below example, we specify a <code class="highlighter-rouge">gdemo</code> model which accepts two inputs, <code class="highlighter-rouge">x</code> and <code class="highlighter-rouge">y</code>.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
  <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="k">return</span> <span class="n">x</span><span class="x">,</span> <span class="n">y</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Assign the function without inputs to a variable, and Turing will produce a sample from the prior distribution.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Samples from p(x,y)</span>
<span class="n">g_prior_sampler</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">()</span>
<span class="n">g_prior_sampler</span><span class="x">()</span>
</code></pre></div></div>

<p>Output:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.685690547873451, -1.1972706455914328)
</code></pre></div></div>

<p><a id="Sampling-from-a-Conditional-Distribution-(The-Posterior)-1"></a></p>

<h3 id="sampling-from-a-conditional-distribution-the-posterior">Sampling from a Conditional Distribution (The Posterior)</h3>

<p><a id="Using-Missing-1"></a></p>

<h4 id="using-missing">Using <code class="highlighter-rouge">Missing</code></h4>

<p>Values that are <code class="highlighter-rouge">missing</code> are treated as parameters to be estimated. This can be useful if you want to simulate draws for that parameter, or if you are sampling from a conditional distribution. Turing v0.6.7 supports the following syntax:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="c"># Treat x as a vector of missing values.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">fill</span><span class="x">(</span><span class="nb">missing</span><span class="x">,</span> <span class="mi">2</span><span class="x">))</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mi">500</span><span class="x">,</span> <span class="mf">0.01</span><span class="x">,</span> <span class="mi">5</span><span class="x">))</span>
</code></pre></div></div>

<p>The above case tells the model compiler the dimensions of the values it needs to generate. The generated values for <code class="highlighter-rouge">x</code> can be extracted from the <code class="highlighter-rouge">Chains</code> object using <code class="highlighter-rouge">c[:x]</code>.</p>

<p>Currently, Turing does not support vector-valued inputs containing mixed <code class="highlighter-rouge">missing</code> and non-missing values, i.e. vectors of type <code class="highlighter-rouge">Union{Missing, T}</code> where <code class="highlighter-rouge">T</code> is any type. The following <strong>will not work</strong>:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">eachindex</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="c"># Warning: This will provide an error!</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">([</span><span class="nb">missing</span><span class="x">,</span> <span class="mf">2.4</span><span class="x">])</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mi">500</span><span class="x">,</span> <span class="mf">0.01</span><span class="x">,</span> <span class="mi">5</span><span class="x">))</span>
</code></pre></div></div>

<p>If this is functionality you need, you may need to define each parameter as a separate variable, as below:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">x1</span><span class="x">,</span> <span class="n">x2</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="c"># Note that x1 and x2 are no longer vector-valued.</span>
    <span class="n">x1</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x2</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>

<span class="c"># Equivalent to sampling p( x1 | x2 = 1.5).</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gdemo</span><span class="x">(</span><span class="nb">missing</span><span class="x">,</span> <span class="mf">1.5</span><span class="x">)</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mi">500</span><span class="x">,</span> <span class="mf">0.01</span><span class="x">,</span> <span class="mi">5</span><span class="x">))</span>
</code></pre></div></div>

<p><a id="Using-Argument-Defaults-1"></a></p>

<h4 id="using-argument-defaults">Using Argument Defaults</h4>

<p>Turing models can also be treated as generative by providing default values in the model declaration, and then calling that model without arguments.</p>

<p>Suppose we wish to generate data according to the model</p>

<script type="math/tex; mode=display">s \sim \text{InverseGamma}(2,3) \\
m \sim \text{Normal}(0,\sqrt{s}) \\
x_i \sim \text{Normal}(m, \sqrt{s}), \space i = 1\dots10</script>

<p>Each <script type="math/tex">x_i</script> can be generated by Turing. In the model below, if <code class="highlighter-rouge">x</code> is not provided when the function is called, <code class="highlighter-rouge">x</code> will default to <code class="highlighter-rouge">Vector{Real}(undef, 10)</code>, a 10-element array of <code class="highlighter-rouge">Real</code> values. The sampler will then treat <code class="highlighter-rouge">x</code> as a parameter and generate those quantities.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Turing</span>

<span class="c"># Declare a model with a default value.</span>
<span class="nd">@model</span> <span class="n">generative</span><span class="x">(</span><span class="n">x</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="n">Real</span><span class="x">}(</span><span class="n">undef</span><span class="x">,</span> <span class="mi">10</span><span class="x">))</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
        <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">s</span><span class="x">,</span> <span class="n">m</span>
<span class="k">end</span>
</code></pre></div></div>

<p>This model can be called in a traditional fashion, with an argument vector of any size:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The values 1.5 and 2.0 will be observed by the sampler.</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">generative</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span><span class="mf">2.0</span><span class="x">])</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mi">1000</span><span class="x">,</span> <span class="mf">0.01</span><span class="x">,</span> <span class="mi">5</span><span class="x">))</span>
</code></pre></div></div>

<p>We can generate observations by providing no arguments in the <code class="highlighter-rouge">sample</code> call.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># This call will generate a vector of 10 values</span>
<span class="c"># every sampler iteration.</span>
<span class="n">generated</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">generative</span><span class="x">(),</span> <span class="n">HMC</span><span class="x">(</span><span class="mi">1000</span><span class="x">,</span> <span class="mf">0.01</span><span class="x">,</span> <span class="mi">5</span><span class="x">))</span>
</code></pre></div></div>

<p>The generated quantities can then be accessed by pulling them out of the chain. To access all the <code class="highlighter-rouge">x</code> values, we first subset the chain using <code class="highlighter-rouge">generated[:x]</code></p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xs</span> <span class="o">=</span> <span class="n">generated</span><span class="x">[</span><span class="o">:</span><span class="n">x</span><span class="x">]</span>
</code></pre></div></div>

<p>You can access the values inside a chain several ways:</p>

<ol>
  <li>Turn them into a <code class="highlighter-rouge">DataFrame</code> object</li>
  <li>Use their raw <code class="highlighter-rouge">AxisArray</code> form</li>
  <li>Create a three-dimensional <code class="highlighter-rouge">Array</code> object</li>
</ol>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Convert to a DataFrame.</span>
<span class="n">DataFrame</span><span class="x">(</span><span class="n">xs</span><span class="x">)</span>

<span class="c"># Retrieve an AxisArray.</span>
<span class="n">xs</span><span class="o">.</span><span class="n">value</span>

<span class="c"># Retrieve a basic 3D Array.</span>
<span class="n">xs</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">data</span>
</code></pre></div></div>

<p><a id="What-to-Use-as-a-Default-Value-1"></a></p>

<h4 id="what-to-use-as-a-default-value">What to Use as a Default Value</h4>

<p>Currently, the actual <em>value</em> of the default argument does not matter. Only the dimensions and type of a non-atomic value are relevant. Turing uses default values to pre-allocate vectors when they are treated as parameters, because if the value is not provided, the model will not know the size or type of a vector. Consider the following model:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">generator</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
  <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
      <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="k">end</span>
  <span class="k">return</span> <span class="n">s</span><span class="x">,</span> <span class="n">m</span>
<span class="k">end</span>
</code></pre></div></div>

<p>If we are trying to generate random random values from the <code class="highlighter-rouge">generator</code> model and we call <code class="highlighter-rouge">sample(generator(), HMC(1000, 0.01, 5))</code>, we will receive an error. This is because there is no way to determine <code class="highlighter-rouge">length(x)</code>, whether <code class="highlighter-rouge">x</code> is a vector, and the type of the values in <code class="highlighter-rouge">x</code>.</p>

<p>A sensible default value might be:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">generator</span><span class="x">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">zeros</span><span class="x">(</span><span class="mi">10</span><span class="x">))</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
  <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="x">(</span><span class="n">x</span><span class="x">)</span>
      <span class="n">x</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
  <span class="k">end</span>
  <span class="k">return</span> <span class="n">s</span><span class="x">,</span> <span class="n">m</span>
<span class="k">end</span>
</code></pre></div></div>

<p>In this case, the model compiler can now determine that <code class="highlighter-rouge">x</code> is a <code class="highlighter-rouge">Vector{Float64,1}</code> of length 10, and the model will work as intended. It doesn’t matter what the values in the vector are — at current, <code class="highlighter-rouge">x</code> will be treated as a parameter if it assumes its default value, i.e. no value was provided in the function call for that variable.</p>

<p>The element type of the vector (or matrix) should match the type of the random variable, <code class="highlighter-rouge">&lt;: Integer</code> for discrete random variables and <code class="highlighter-rouge">&lt;: AbstractFloat</code> for continuous random variables. Moreover, if the continuous random variable is to be sampled using a Hamiltonian sampler, the vector’s element type needs to be <code class="highlighter-rouge">Real</code> to enable auto-differentiation through the model which uses special number types that are sub-types of <code class="highlighter-rouge">Real</code>. Finally, when using a particle sampler, a <code class="highlighter-rouge">TArray</code> should be used.</p>

<p><a id="Beyond-the-Basics-1"></a></p>

<h2 id="beyond-the-basics">Beyond the Basics</h2>

<p><a id="Compositional-Sampling-Using-Gibbs-1"></a></p>

<h3 id="compositional-sampling-using-gibbs">Compositional Sampling Using Gibbs</h3>

<p>Turing.jl provides a Gibbs interface to combine different samplers. For example, one can combine an <code class="highlighter-rouge">HMC</code> sampler with a <code class="highlighter-rouge">PG</code> sampler to run inference for different parameters in a single model as below.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">simple_choice</span><span class="x">(</span><span class="n">xs</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
  <span class="n">p</span> <span class="o">~</span> <span class="n">Beta</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
  <span class="n">z</span> <span class="o">~</span> <span class="n">Bernoulli</span><span class="x">(</span><span class="n">p</span><span class="x">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="x">(</span><span class="n">xs</span><span class="x">)</span>
    <span class="k">if</span> <span class="n">z</span> <span class="o">==</span> <span class="mi">1</span>
      <span class="n">xs</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="k">else</span>
      <span class="n">xs</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>

<span class="n">simple_choice_f</span> <span class="o">=</span> <span class="n">simple_choice</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">,</span> <span class="mf">0.3</span><span class="x">])</span>

<span class="n">chn</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">simple_choice_f</span><span class="x">,</span> <span class="n">Gibbs</span><span class="x">(</span><span class="mi">1000</span><span class="x">,</span> <span class="n">HMC</span><span class="x">(</span><span class="mi">1</span><span class="x">,</span><span class="mf">0.2</span><span class="x">,</span><span class="mi">3</span><span class="x">,</span><span class="o">:</span><span class="n">p</span><span class="x">),</span> <span class="n">PG</span><span class="x">(</span><span class="mi">20</span><span class="x">,</span><span class="mi">1</span><span class="x">,</span><span class="o">:</span><span class="n">z</span><span class="x">)))</span>
</code></pre></div></div>

<p>The <code class="highlighter-rouge">Gibbs</code> sampler can be used to specify unique automatic differentation backends for different variable spaces. Please see the <a href="/docs/autodiff/">Automatic Differentiation</a> article for more.</p>

<p>For more details of compositional sampling in Turing.jl, please check the corresponding <a href="http://xuk.ai/assets/aistats2018-turing.pdf">paper</a>.</p>

<p><a id="Working-with-MCMCChains.jl-1"></a></p>

<h3 id="working-with-mcmcchainsjl">Working with MCMCChains.jl</h3>

<p>Turing.jl wraps its samples using <code class="highlighter-rouge">MCMCChains.Chain</code> so that all the functions working for <code class="highlighter-rouge">MCMCChains.Chain</code> can be re-used in Turing.jl. Two typical functions are <code class="highlighter-rouge">MCMCChains.describe</code> and <code class="highlighter-rouge">MCMCChains.plot</code>, which can be used as follows for an obtained chain <code class="highlighter-rouge">chn</code>. For more information on <code class="highlighter-rouge">MCMCChains</code>, please see the <a href="https://github.com/TuringLang/MCMCChains.jl">GitHub repository</a>.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">describe</span><span class="x">(</span><span class="n">chn</span><span class="x">)</span> <span class="c"># Lists statistics of the samples.</span>
<span class="n">plot</span><span class="x">(</span><span class="n">chn</span><span class="x">)</span> <span class="c"># Plots statistics of the samples.</span>
</code></pre></div></div>

<p>There are numerous functions in addition to <code class="highlighter-rouge">describe</code> and <code class="highlighter-rouge">plot</code> in the <code class="highlighter-rouge">MCMCChains</code> package, such as those used in convergence diagnostics. For more information on the package, please see the <a href="https://github.com/TuringLang/MCMCChains.jl">GitHub repository</a>.</p>

<p><a id="Working-with-Libtask.jl-1"></a></p>

<h3 id="working-with-libtaskjl">Working with Libtask.jl</h3>

<p>The <a href="https://github.com/TuringLang/Libtask.jl">Libtask.jl</a> library provides write-on-copy data structures that are safe for use in Turing’s particle-based samplers. One data structure in particular is often required for use – the <a href="http://turing.ml/docs/library/#Libtask.TArray"><code class="highlighter-rouge">TArray</code></a>. The following sampler types require the use of a <code class="highlighter-rouge">TArray</code> to store distributions:</p>

<ul>
  <li><code class="highlighter-rouge">IPMCMC</code></li>
  <li><code class="highlighter-rouge">IS</code></li>
  <li><code class="highlighter-rouge">PG</code></li>
  <li><code class="highlighter-rouge">PMMH</code></li>
  <li><code class="highlighter-rouge">SMC</code></li>
</ul>

<p>If you do not use a <code class="highlighter-rouge">TArray</code> to store arrays of distributions when using a particle-based sampler, you may experience errors.</p>

<p>Here is an example of how the <code class="highlighter-rouge">TArray</code> (using a <code class="highlighter-rouge">TArray</code> constructor function called <code class="highlighter-rouge">tzeros</code>) can be applied in this way:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Turing model definition.</span>
<span class="nd">@model</span> <span class="n">BayesHmm</span><span class="x">(</span><span class="n">y</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="c"># Declare a TArray with a length of N.</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">tzeros</span><span class="x">(</span><span class="kt">Int</span><span class="x">,</span> <span class="n">N</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="n">Real</span><span class="x">}(</span><span class="n">undef</span><span class="x">,</span> <span class="n">K</span><span class="x">)</span>
    <span class="n">T</span> <span class="o">=</span> <span class="kt">Vector</span><span class="x">{</span><span class="kt">Vector</span><span class="x">{</span><span class="n">Real</span><span class="x">}}(</span><span class="n">undef</span><span class="x">,</span> <span class="n">K</span><span class="x">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="n">K</span>
        <span class="n">T</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Dirichlet</span><span class="x">(</span><span class="n">ones</span><span class="x">(</span><span class="n">K</span><span class="x">)</span><span class="o">/</span><span class="n">K</span><span class="x">)</span>
        <span class="n">m</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="mf">0.01</span><span class="x">)</span>
    <span class="k">end</span>

    <span class="c"># Draw from a distribution for each element in s.</span>
    <span class="n">s</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span> <span class="o">~</span> <span class="n">Categorical</span><span class="x">(</span><span class="n">K</span><span class="x">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="o">:</span><span class="n">N</span>
        <span class="n">s</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Categorical</span><span class="x">(</span><span class="n">vec</span><span class="x">(</span><span class="n">T</span><span class="x">[</span><span class="n">s</span><span class="x">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="x">]]))</span>
        <span class="n">y</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">[</span><span class="n">s</span><span class="x">[</span><span class="n">i</span><span class="x">]],</span> <span class="mf">0.1</span><span class="x">)</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="x">(</span><span class="n">s</span><span class="x">,</span> <span class="n">m</span><span class="x">)</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p><a id="Changing-Default-Settings-1"></a></p>

<h3 id="changing-default-settings">Changing Default Settings</h3>

<p>Some of Turing.jl’s default settings can be changed for better usage.</p>

<p><a id="AD-Chunk-Size-1"></a></p>

<h4 id="ad-chunk-size">AD Chunk Size</h4>

<p>ForwardDiff (Turing’s default AD backend) uses forward-mode chunk-wise AD. The chunk size can be manually set by <code class="highlighter-rouge">setchunksize(new_chunk_size)</code>; alternatively, use an auto-tuning helper function <code class="highlighter-rouge">auto_tune_chunk_size!(mf::Function, rep_num=10)</code>, which will profile various chunk sizes. Here <code class="highlighter-rouge">mf</code> is the model function, e.g. <code class="highlighter-rouge">gdemo(1.5, 2)</code>, and <code class="highlighter-rouge">rep_num</code> is the number of repetitions during profiling.</p>

<p><a id="AD-Backend-1"></a></p>

<h4 id="ad-backend">AD Backend</h4>

<p>Since <a href="https://github.com/TuringLang/Turing.jl/pull/428">#428</a>, Turing.jl supports <code class="highlighter-rouge">Tracker</code> as backend for reverse mode autodiff. To switch between <code class="highlighter-rouge">ForwardDiff.jl</code> and <code class="highlighter-rouge">Tracker</code>, one can call function <code class="highlighter-rouge">setadbackend(backend_sym)</code>, where <code class="highlighter-rouge">backend_sym</code> can be <code class="highlighter-rouge">:forward_diff</code> or <code class="highlighter-rouge">:reverse_diff</code>.</p>

<p>For more information on Turing’s automatic differentiation backend, please see the <a href="/docs/autodiff/">Automatic Differentiation</a> article.</p>

<p><a id="Progress-Meter-1"></a></p>

<h4 id="progress-meter">Progress Meter</h4>

<p>Turing.jl uses ProgressMeter.jl to show the progress of sampling, which may lead to slow down of inference or even cause bugs in some IDEs due to I/O. This can be turned on or off by <code class="highlighter-rouge">turnprogress(true)</code> and <code class="highlighter-rouge">turnprogress(false)</code>, of which the former is set as default.</p>


        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      
  <nav class="pagination">
    
      <a href="/docs/get-started/" class="pagination--pager prev" title="Getting Started
">Previous: Getting Started
</a>
    
    
      <a href="/docs/" class="pagination--pager next" title="Turing Documentation
">Next: Turing Documentation
</a>
    
  </nav>


    </div>

    
  </article>

  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="text" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>
      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <!-- 
<div class="page__footer-copyright">&copy; 2019 Turing.jl
 -->
      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.3.1/js/all.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>





  </body>
</html>
